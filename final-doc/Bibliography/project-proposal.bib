
@article{barbu_data_nodate,
	title = {Data {Mining} {Tool} for {Academic} {Data} {Exploitation}},
	language = {en},
	author = {Barbu, M and Vilanova, R and Vicario, J Lopez and Varanda, M J and Alves, P and Podpora, M and Prada, M A and Torrebruno, A and Marin, S and Tocu, R},
	pages = {62},
	file = {Data Mining Tool for Academic Data Exploitation.pdf:/Users/angelsarmiento/Documents/Graduate/Project/angel_research/Data Mining Tool for Academic Data Exploitation.pdf:application/pdf},
}

@article{romero_educational_2020,
	title = {Educational data mining and learning analytics: {An} updated survey},
	volume = {10},
	issn = {1942-4787, 1942-4795},
	shorttitle = {Educational data mining and learning analytics},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/widm.1355},
	doi = {10.1002/widm.1355},
	abstract = {This survey is an updated and improved version of the previous one published in 2013 in this journal with the title “data mining in education”. It reviews in a comprehensible and very general way how Educational Data Mining and Learning Analytics have been applied over educational data. In the last decade, this research area has evolved enormously and a wide range of related terms are now used in the bibliography such as Academic Analytics, Institutional Analytics, Teaching Analytics, Data-Driven Education, Data-Driven Decision-Making in Education, Big Data in Education, and Educational Data Science. This paper provides the current state of the art by reviewing the main publications, the key milestones, the knowledge discovery cycle, the main educational environments, the specific tools, the free available datasets, the most used methods, the main objectives, and the future trends in this research area.},
	language = {en},
	number = {3},
	urldate = {2021-09-22},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Romero, Cristobal and Ventura, Sebastian},
	month = may,
	year = {2020},
	file = {Educational data mining and learning analytics- An updated survey.pdf:/Users/angelsarmiento/Documents/Graduate/Project/angel_research/Educational data mining and learning analytics- An updated survey.pdf:application/pdf},
}

@article{hilliger_evaluating_2019,
	title = {Evaluating {Usage} of an {Analytics} {Tool} to {Support} {Continuous} {Curriculum} {Improvement}},
	abstract = {Curriculum analytics (CA) consists of using analytical tools to collect and analyse educational data, such as program structure and course grading, to improve curriculum development and program quality. This paper presents an instrumental case study to illustrate the usage of a CA tool to help teaching staff collect evidence of competency attainment in an engineering school in Latin America. The CA tool was implemented during a 3-year continuous improvement process, in the context of an international accreditation. We collected and analysed data before and after tool implementation to evaluate its use by 124 teaching staff from 96 course sections. Data collection techniques included: analysis of documentary evidence collected for the continuous improvement process and teaching staff questionnaires. Findings show that the tool supported staff tasks related to the assessment of competency attainment at a program level. However, usability and functionality issues would have to be addressed to also support course redesign, providing actionable information about students’ performance at an individual level. Lessons learned imply that institutions could adapt and adopt existing CA tools to support curriculum analysis by not only investing in tool development, but also in capacity building for its use for continuous improvement processes.},
	language = {en},
	author = {Hilliger, Isabel and Miranda, Constanza and Celis, Sergio and Pérez-SanAgustín, Mar},
	year = {2019},
	pages = {14},
	file = {Hilliger et al. - 2019 - Evaluating Usage of an Analytics Tool to Support C.pdf:/Users/angelsarmiento/Zotero/storage/CM3EJV9H/Hilliger et al. - 2019 - Evaluating Usage of an Analytics Tool to Support C.pdf:application/pdf},
}

@article{rose_explanatory_2019,
	title = {Explanatory learner models: {Why} machine learning (alone) is not the answer},
	volume = {50},
	issn = {0007-1013, 1467-8535},
	shorttitle = {Explanatory learner models},
	url = {https://onlinelibrary.wiley.com/doi/10.1111/bjet.12858},
	doi = {10.1111/bjet.12858},
	abstract = {Using data to understand learning and improve education has great promise. However, the promise will not be achieved simply by AI and Machine Learning researchers developing innovative models that more accurately predict labeled data. As AI advances, modeling techniques and the models they produce are getting increasingly complex, often involving tens of thousands of parameters or more. Though strides towards interpretation of complex models are being made in core machine learning communities, it remains true in these cases of “black box” modeling that research teams may have little possibility to peer inside to try understand how, why, or even whether such models will work when applied beyond the data on which they were built. Rather than relying on AI expertise alone, we suggest that learning engineering teams bring interdisciplinary expertise to bear to develop explanatory learner models that provide interpretable and actionable insights in addition to accurate prediction. We describe examples that illustrate use of different kinds of data (eg, click stream and discourse data) in different course content (eg, math and writing) and toward different goals (eg, improving student models and generating actionable feedback). We recommend learning engineering teams, shared infrastructure and funder incentives toward better explanatory learner model development that advances learning science, produces better pedagogical practices and demonstrably improves student learning.},
	language = {en},
	number = {6},
	urldate = {2021-09-22},
	journal = {British Journal of Educational Technology},
	author = {Rosé, Carolyn P. and McLaughlin, Elizabeth A. and Liu, Ran and Koedinger, Kenneth R.},
	month = nov,
	year = {2019},
	pages = {2943--2958},
	file = {Rosé et al. - 2019 - Explanatory learner models Why machine learning (.pdf:/Users/angelsarmiento/Zotero/storage/IKVVIWE7/Rosé et al. - 2019 - Explanatory learner models Why machine learning (.pdf:application/pdf},
}

@book{columbia_university_usa_handbook_2017,
	edition = {First},
	title = {Handbook of {Learning} {Analytics}},
	isbn = {978-0-9952408-0-3},
	url = {https://solaresearch.org/hla-17/},
	language = {en},
	urldate = {2021-09-22},
	publisher = {Society for Learning Analytics Research (SoLAR)},
	editor = {{Columbia University, USA} and Lang, Charles and Siemens, George and {University of Texas at Arlington, USA} and Wise, Alyssa and {New York University, USA} and Gasevic, Dragan and {University of Edinburgh, UK}},
	month = may,
	year = {2017},
	doi = {10.18608/hla17},
	file = {Columbia University, USA et al. - 2017 - Handbook of Learning Analytics.pdf:/Users/angelsarmiento/Zotero/storage/IIYTE5JH/Columbia University, USA et al. - 2017 - Handbook of Learning Analytics.pdf:application/pdf},
}

@article{ifenthaler_utilising_2020,
	title = {Utilising learning analytics to support study success in higher education: a systematic review},
	volume = {68},
	issn = {1042-1629, 1556-6501},
	shorttitle = {Utilising learning analytics to support study success in higher education},
	url = {https://link.springer.com/10.1007/s11423-020-09788-z},
	doi = {10.1007/s11423-020-09788-z},
	abstract = {Study success includes the successful completion of a first degree in higher education to the largest extent, and the successful completion of individual learning tasks to the smallest extent. Factors affecting study success range from individual dispositions (e.g., motivation, prior academic performance) to characteristics of the educational environment (e.g., attendance, active learning, social embeddedness). Recent developments in learning analytics, which are a socio-technical data mining and analytic practice in educational contexts, show promise in enhancing study success in higher education, through the collection and analysis of data from learners, learning processes, and learning environments in order to provide meaningful feedback and scaffolds when needed. This research reports a systematic review focusing on empirical evidence, demonstrating how learning analytics have been successful in facilitating study success in continuation and completion of students’ university courses. Using standardised steps of conducting a systematic review, an initial set of 6220 articles was identified. The final sample includes 46 key publications. The findings obtained in this systematic review suggest that there are a considerable number of learning analytics approaches which utilise effective techniques in supporting study success and students at risk of dropping out. However, rigorous, large-scale evidence of the effectiveness of learning analytics in supporting study success is still lacking. The tested variables, algorithms, and methods collected in this systematic review can be used as a guide in helping researchers and educators to further improve the design and implementation of learning analytics systems.},
	language = {en},
	number = {4},
	urldate = {2021-09-22},
	journal = {Educational Technology Research and Development},
	author = {Ifenthaler, Dirk and Yau, Jane Yin-Kim},
	month = aug,
	year = {2020},
	pages = {1961--1990},
	file = {Ifenthaler and Yau - 2020 - Utilising learning analytics to support study succ.pdf:/Users/angelsarmiento/Zotero/storage/7RFRREAQ/Ifenthaler and Yau - 2020 - Utilising learning analytics to support study succ.pdf:application/pdf},
}

@article{reddy_learning_nodate,
	title = {Learning {Representations} of {Student} {Knowledge} and {Educational} {Content}},
	abstract = {Students in online courses generate large amounts of data that can be used to personalize the learning process and improve quality of education. The goal of this work is to develop a statistical model of students and educational content that can be used for a variety of tasks, such as adaptive lesson sequencing and learning analytics. We formulate this problem as a regularized maximum-likelihood embedding of students, lessons, and assessments from historical student-module interactions. Akin to collaborative ﬁltering for recommender systems, the algorithm does not require students or modules to be described by features, but it learns a representation using access traces. An empirical evaluation on large-scale data from Knewton, an adaptive learning technology company, shows that this approach predicts assessment results more accurately than baseline models and is able to discriminate between lesson sequences that lead to mastery and failure.},
	language = {en},
	author = {Reddy, Siddharth and Labutov, Igor and Joachims, Thorsten},
	pages = {14},
	file = {Reddy et al. - Learning Representations of Student Knowledge and .pdf:/Users/angelsarmiento/Zotero/storage/MDXTGEYM/Reddy et al. - Learning Representations of Student Knowledge and .pdf:application/pdf},
}

@article{lan_sparse_nodate,
	title = {Sparse {Factor} {Analysis} for {Learning} and {Content} {Analytics}},
	abstract = {We develop a new model and algorithms for machine learning-based learning analytics, which estimate a learner’s knowledge of the concepts underlying a domain, and content analytics, which estimate the relationships among a collection of questions and those concepts. Our model represents the probability that a learner provides the correct response to a question in terms of three factors: their understanding of a set of underlying concepts, the concepts involved in each question, and each question’s intrinsic diﬃculty. We estimate these factors given the graded responses to a collection of questions. The underlying estimation problem is ill-posed in general, especially when only a subset of the questions are answered. The key observation that enables a well-posed solution is the fact that typical educational domains of interest involve only a small number of key concepts. Leveraging this observation, we develop both a bi-convex maximum-likelihood-based solution and a Bayesian solution to the resulting SPARse Factor Analysis (SPARFA) problem. We also incorporate user-deﬁned tags on questions to facilitate the interpretability of the estimated factors. Experiments with synthetic and real-world data demonstrate the eﬃcacy of our approach. Finally, we make a connection between SPARFA and noisy, binary-valued (1-bit) dictionary learning that is of independent interest.},
	language = {en},
	author = {Lan, Andrew S and Waters, Andrew E and Studer, Christoph and Baraniuk, Richard G},
	pages = {50},
	file = {Lan et al. - Sparse Factor Analysis for Learning and Content An.pdf:/Users/angelsarmiento/Zotero/storage/6Z3AZQUJ/Lan et al. - Sparse Factor Analysis for Learning and Content An.pdf:application/pdf},
}

@article{lan_tag-aware_2014,
	title = {Tag-{Aware} {Ordinal} {Sparse} {Factor} {Analysis} for {Learning} and {Content} {Analytics}},
	url = {http://arxiv.org/abs/1412.5967},
	abstract = {Machine learning oﬀers novel ways and means to design personalized learning systems wherein each student’s educational experience is customized in real time depending on their background, learning goals, and performance to date. SPARse Factor Analysis (SPARFA) is a novel framework for machine learning-based learning analytics, which estimates a learner’s knowledge of the concepts underlying a domain, and content analytics, which estimates the relationships among a collection of questions and those concepts. SPARFA jointly learns the associations among the questions and the concepts, learner concept knowledge proﬁles, and the underlying question diﬃculties, solely based on the correct/incorrect graded responses of a population of learners to a collection of questions. In this paper, we extend the SPARFA framework signiﬁcantly to enable: (i) the analysis of graded responses on an ordinal scale (partial credit) rather than a binary scale (correct/incorrect); (ii) the exploitation of tags/labels for questions that partially describe the question–concept associations. The resulting Ordinal SPARFA-Tag framework greatly enhances the interpretability of the estimated concepts. We demonstrate using real educational data that Ordinal SPARFA-Tag outperforms both SPARFA and existing collaborative ﬁltering techniques in predicting missing learner responses.},
	language = {en},
	urldate = {2021-09-22},
	journal = {arXiv:1412.5967 [cs, stat]},
	author = {Lan, Andrew S. and Studer, Christoph and Waters, Andrew E. and Baraniuk, Richard G.},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.5967},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Lan et al. - 2014 - Tag-Aware Ordinal Sparse Factor Analysis for Learn.pdf:/Users/angelsarmiento/Zotero/storage/9L7SKHDY/Lan et al. - 2014 - Tag-Aware Ordinal Sparse Factor Analysis for Learn.pdf:application/pdf},
}

@article{sarmiento_cdio_curriculum_map_nodate,
	title = {{CDIO}\_curriculum\_map},
	abstract = {This paper describes the creation of a mathematical model that represents the mapping of an undergraduate engineering degree program to the CDIO syllabus. A network model represents entities as nodes and relationships among entities as links between nodes. In the CDIO curriculum mapping network model, CDIO skills and program courses are modeled as entities. The network model defines directed relationships to represent the mapping between courses and CDIO skills. A relationship exists if a course addresses a CDIO skill. The result is a structured model on which we build scalable educational analytics and data visualization tools. The approach is demonstrated for the MIT undergraduate program in Aerospace Engineering.},
	language = {en},
	author = {Sarmiento, Angel},
	pages = {11},
	file = {Sarmiento - CDIO_curriculum_map.pdf:/Users/angelsarmiento/Zotero/storage/ZEJ5ZDBJ/Sarmiento - CDIO_curriculum_map.pdf:application/pdf},
}

@article{willcox_network_2017,
	title = {Network models for mapping educational data},
	volume = {3},
	issn = {2053-4701},
	url = {https://www.cambridge.org/core/product/identifier/S205347011700018X/type/journal_article},
	doi = {10.1017/dsj.2017.18},
	abstract = {Educational mapping is the process of analyzing an educational system to identify entities, relationships and attributes. This paper proposes a network modeling approach to educational mapping. Current mapping processes in education typically represent data in forms that do not support scalable learning analytics. For example, a curriculum map is usually a table, where relationships among curricular elements are represented implicitly in the rows of the table. The proposed network modeling approach overcomes this limitation through explicit modeling of these relationships in a graph structure, which in turn unlocks the ability to perform scalable analyses on the dataset. The paper presents network models for educational use cases, with concrete examples in curriculum mapping, accreditation mapping and concept mapping. Illustrative examples demonstrate how the formal modeling approach enables visualization and learning analytics. The analysis provides insight into learning pathways, supporting design of adaptive learning systems. It also permits gap analysis of curriculum coverage, supporting student advising, student degree planning and curricular design at scales ranging from an entire institution to an individual course.},
	language = {en},
	urldate = {2021-09-26},
	journal = {Design Science},
	author = {Willcox, Karen E. and Huang, Luwen},
	year = {2017},
	pages = {e18},
	file = {Willcox and Huang - 2017 - Network models for mapping educational data.pdf:/Users/angelsarmiento/Zotero/storage/MKDHLUVW/Willcox and Huang - 2017 - Network models for mapping educational data.pdf:application/pdf},
}

@misc{noauthor_notitle_nodate,
}

@article{willcox_mapping_nodate,
	title = {{MAPPING} {THE} {CDIO} {CURRICULUM} {WITH} {NETWORK} {MODELS}},
	abstract = {This paper describes the creation of a mathematical model that represents the mapping of an undergraduate engineering degree program to the CDIO syllabus. A network model represents entities as nodes and relationships among entities as links between nodes. In the CDIO curriculum mapping network model, CDIO skills and program courses are modeled as entities. The network model defines directed relationships to represent the mapping between courses and CDIO skills. A relationship exists if a course addresses a CDIO skill. The result is a structured model on which we build scalable educational analytics and data visualization tools. The approach is demonstrated for the MIT undergraduate program in Aerospace Engineering.},
	language = {en},
	author = {Willcox, Karen E and Huang, Luwen},
	pages = {11},
	file = {Willcox and Huang - MAPPING THE CDIO CURRICULUM WITH NETWORK MODELS.pdf:/Users/angelsarmiento/Zotero/storage/5NXLKLUK/Willcox and Huang - MAPPING THE CDIO CURRICULUM WITH NETWORK MODELS.pdf:application/pdf},
}

@article{jjs,
 title={Multidimensional Scaling Using Majorization: SMACOF in R},
 volume={31},
 url={https://www.jstatsoft.org/index.php/jss/article/view/v031i03},
 doi={10.18637/jss.v031.i03},
 abstract={In this paper we present the methodology of multidimensional scaling problems (MDS) solved by means of the majorization algorithm. The objective function to be minimized is known as stress and functions which majorize stress are elaborated. This strategy to solve MDS problems is called SMACOF and it is implemented in an &amp;lt;b&amp;gt;R&amp;lt;/b&amp;gt; package of the same name which is presented in this article. We extend the basic SMACOF theory in terms of configuration constraints, three-way data, unfolding models, and projection of the resulting configurations onto spheres and other quadratic surfaces. Various examples are presented to show the possibilities of the SMACOF approach offered by the corresponding package.},
 number={3},
 journal={Journal of Statistical Software},
 author={de Leeuw, Jan and Mair, Patrick},
 year={2009},
 pages={1–30}
}

@article{lda_pap, 
author = {Blei, David M. and Ng, Andrew Y. and Jordan, Michael I.}, 
title = {Latent Dirichlet Allocation}, 
year = {2003}, 
issue_date = {3/1/2003}, 
publisher = {JMLR.org}, 
volume = {3}, 
number = {null}, 
issn = {1532-4435}, 
abstract = {We describe latent Dirichlet allocation (LDA), 
a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.}, 
journal = {J. Mach. Learn. Res.}, 
month = {mar}, 
pages = {993–1022}, 
numpages = {30} 
}

@InProceedings{regex,
author="Erwig, Martin
and Gopinath, Rahul",
editor="de Lara, Juan
and Zisman, Andrea",
title="Explanations for Regular Expressions",
booktitle="Fundamental Approaches to Software Engineering",
year="2012",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="394--408",
abstract="Regular expressions are widely used, but they are inherently hard to understand and (re)use, which is primarily due to the lack of abstraction mechanisms that causes regular expressions to grow large very quickly. The problems with understandability and usability are further compounded by the viscosity, redundancy, and terseness of the notation. As a consequence, many different regular expressions for the same problem are floating around, many of them erroneous, making it quite difficult to find and use the right regular expression for a particular problem. Due to the ubiquitous use of regular expressions, the lack of understandability and usability becomes a serious software engineering problem.",
isbn="978-3-642-28872-2"
}

@book{zipf2013psycho,
  title={The psycho-biology of language: An introduction to dynamic philology},
  author={Zipf, George Kingsley},
  year={2013},
  publisher={Routledge}
}

@article{burrow,
    author = {Burrows, John},
    title = "{‘Delta’: a Measure of Stylistic Difference and a Guide to Likely Authorship}",
    journal = {Literary and Linguistic Computing},
    volume = {17},
    number = {3},
    pages = {267-287},
    year = {2002},
    month = {09},
    abstract = "{This paper is a companion to my ‘Questions of authorship: attribution and beyond’, in which I sketched a new way of using the relative frequencies of the very common words for comparing written texts and testing their likely authorship. The main emphasis of that paper was not on the new procedure but on the broader consequences of our increasing sophistication in making such comparisons and the increasing (although never absolute) reliability of our inferences about authorship. My present objects, accordingly, are to give a more complete account of the procedure itself; to report the outcome of an extensive set of trials; and to consider the strengths and limitations of the new procedure. The procedure offers a simple but comparatively accurate addition to our current methods of distinguishing the most likely author of texts exceeding about 1,500 words in length. It is of even greater value as a method of reducing the field of likely candidates for texts of as little as 100 words in length. Not unexpectedly, it works least well with texts of a genre uncharacteristic of their author and, in one case, with texts far separated in time across a long literary career. Its possible use for other classificatory tasks has not yet been investigated.}",
    issn = {0268-1145},
    doi = {10.1093/llc/17.3.267},
    url = {https://doi.org/10.1093/llc/17.3.267},
    eprint = {https://academic.oup.com/dsh/article-pdf/17/3/267/2743069/170267.pdf},
}


